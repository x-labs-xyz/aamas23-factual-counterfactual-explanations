{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6a8960-a790-4ac5-956b-f0c141cf05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from numpy import std, mean, sqrt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bcf26b-3d07-4200-8cb7-d689b4b8ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define performance gain function\n",
    "def treatment_gain(treatment_avg, baseline_avg, ra_average):\n",
    "    return((treatment_avg - baseline_avg)/(ra_average - baseline_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8772f3-dbaa-4e56-85a3-997d172df5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv files into dataframes\n",
    "workers = pd.read_csv('datasets/participants.csv')\n",
    "results = pd.read_csv('datasets/results.csv')\n",
    "sample = pd.read_csv('datasets/defendants.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d071b",
   "metadata": {},
   "source": [
    "### Performance Summary - Across Treatments\n",
    "Risk assessment model & participant performance in all treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d81a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk assessment model performance average: 0.7954048896833629\n"
     ]
    }
   ],
   "source": [
    "ra_score_avg_performance = sum(workers['ra_brier_score']) / len(workers)\n",
    "print(\"risk assessment model performance average:\", ra_score_avg_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef882d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant performance average: 0.7443864042915929\n"
     ]
    }
   ],
   "source": [
    "participant_score_avg_performance = sum(workers['participant_brier_score']) / len(workers)\n",
    "print(\"participant performance average:\", participant_score_avg_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322053f-3850-450e-bf02-7038fcc57075",
   "metadata": {},
   "source": [
    "### Treatment 0: Baseline\n",
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593e3024-2b56-4853-9c4b-95b71d401ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant prediction score:  0.7108422939569895\n",
      "performance gain:  -0.0\n"
     ]
    }
   ],
   "source": [
    "baseline_treatment = workers.loc[workers['treatment']==0]\n",
    "baseline_avg = (sum(baseline_treatment['participant_brier_score']) / len(baseline_treatment))\n",
    "print(\"average participant prediction score: \", baseline_avg)\n",
    "print(\"performance gain: \", treatment_gain(baseline_avg, baseline_avg, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86ef5f",
   "metadata": {},
   "source": [
    "#### False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4808efba-6419-4c07-bf6d-87f3a2a28426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant false positive rate:  5.408602150537634\n",
      "average risk assessment model false positive rate:  nan\n"
     ]
    }
   ],
   "source": [
    "part_false_positive_avg = mean(workers.loc[workers['treatment']==0]['false_positive_participant'])\n",
    "ra_false_positive_avg = mean(workers.loc[workers['treatment']==0]['false_positive_ra_black'] + workers.loc[workers['treatment']==0]['false_positive_ra_white'])\n",
    "print('average participant false positive rate: ', part_false_positive_avg)\n",
    "print('average risk assessment model false positive rate: ', ra_false_positive_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890e0ae-c4cf-46fe-a46d-b17031630b8c",
   "metadata": {},
   "source": [
    "### Treatment 1: Risk assessment model only (unexplained)\n",
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a250be41-5a2b-44ff-bd0b-e177de86cb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant prediction score:  0.7552974910215053\n",
      "average risk assessment model prediction score:  0.7907383512795702\n",
      "performance gain  0.556412901390463\n"
     ]
    }
   ],
   "source": [
    "ra_treatment = workers.loc[workers['treatment']==1]\n",
    "part_ra_avg = (sum(ra_treatment['participant_brier_score']) / len(ra_treatment))\n",
    "ra_avg = (sum(ra_treatment['ra_brier_score']) / len(ra_treatment))\n",
    "print(\"average participant prediction score: \",part_ra_avg)\n",
    "print(\"average risk assessment model prediction score: \",ra_avg)\n",
    "print(\"performance gain \", treatment_gain(part_ra_avg, baseline_avg, ra_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "144b613d-9ef5-4056-8717-e21fc5388238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants in treatment and baseline\n",
      "t = 4.952181204461114\n",
      "p = 1.654033953927632e-06\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(ra_treatment['participant_brier_score']),list(baseline_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93fc6ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants and risk assessment model in this treatment\n",
      "t = -6.134892509090908\n",
      "p = 5.097641234515415e-09\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants and risk assessment model in this treatment')\n",
    "t, p = stats.ttest_ind(list(ra_treatment['participant_brier_score']),list(ra_treatment['ra_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793ba2e",
   "metadata": {},
   "source": [
    "#### False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28082dd4-3690-4e25-8297-cf233d78325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant false positive rate:  4.548387096774194\n",
      "average risk assessment model false positive rate:  3.774193548387097\n"
     ]
    }
   ],
   "source": [
    "part_false_positive_avg = mean(workers.loc[workers['treatment']==1]['false_positive_participant'])\n",
    "ra_false_positive_avg = mean(workers.loc[workers['treatment']==1]['false_positive_ra_black'] + workers.loc[workers['treatment']==1]['false_positive_ra_white'])\n",
    "print('average participant false positive rate: ', part_false_positive_avg)\n",
    "print('average risk assessment model false positive rate: ', ra_false_positive_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba9d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in treatment and baseline\n",
      "t = -1.4621305912777358\n",
      "p = 0.14541127040561125\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==1]['false_positive_participant']),list(workers.loc[workers['treatment']==0]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6e122-94d0-454e-bff1-dd76ed1ecafa",
   "metadata": {},
   "source": [
    "### Treatment 2: Diverse Counterfactual\n",
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dfe3c65-2cde-4565-a027-1f6be97000c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant prediction score:  0.7498539326179776\n",
      "average risk assessment model prediction score:  0.7974719100898878\n",
      "performance gain  0.450326809726831\n"
     ]
    }
   ],
   "source": [
    "dcf_treatment = workers.loc[workers['treatment']==2]\n",
    "dcf_avg = (sum(dcf_treatment['participant_brier_score']) / len(dcf_treatment))\n",
    "dcf_ra_avg = (sum(dcf_treatment['ra_brier_score']) / len(dcf_treatment))\n",
    "print(\"average participant prediction score: \",dcf_avg)\n",
    "print(\"average risk assessment model prediction score: \",dcf_ra_avg)\n",
    "print(\"performance gain \", treatment_gain(dcf_avg, baseline_avg, dcf_ra_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f61895-6601-4c51-9a5b-579778ec4720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants in treatment and baseline\n",
      "t = 4.019157106510655\n",
      "p = 8.576195940785335e-05\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(dcf_treatment['participant_brier_score']),list(baseline_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cbcac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants in this treatment and risk assessment model only treatment\n",
      "t = -0.7325351291591108\n",
      "p = 0.46479480836807663\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(dcf_treatment['participant_brier_score']),list(ra_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e83b510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants and risk assessment model in this treatment\n",
      "t = -7.123841474982188\n",
      "p = 2.5860581750219422e-11\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants and risk assessment model in this treatment')\n",
    "t, p = stats.ttest_ind(list(dcf_treatment['participant_brier_score']),list(dcf_treatment['ra_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657aa53",
   "metadata": {},
   "source": [
    "#### False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4303eafd-0d16-4cbe-afe7-dea43cfc6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant false positive rate:  5.269662921348314\n",
      "average RA false positive rate:  3.2134831460674156\n"
     ]
    }
   ],
   "source": [
    "part_false_positive_avg = mean(workers.loc[workers['treatment']==2]['false_positive_participant'])\n",
    "ra_false_positive_avg = mean(workers.loc[workers['treatment']==2]['false_positive_ra_black'] + workers.loc[workers['treatment']==2]['false_positive_ra_white'])\n",
    "print('average participant false positive rate: ', part_false_positive_avg)\n",
    "print('average RA false positive rate: ', ra_false_positive_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7343aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in treatment and baseline\n",
      "t = -0.21039128190777795\n",
      "p = 0.8336002654028125\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==2]['false_positive_participant']),list(workers.loc[workers['treatment']==0]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a59af254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in this treatment and risk assessment model only treatment\n",
      "t = 1.3994348334758961\n",
      "p = 0.16340359157624668\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==2]['false_positive_participant']),list(workers.loc[workers['treatment']==1]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ab8ec-748b-44a1-826d-fe48db333a4b",
   "metadata": {},
   "source": [
    "### Treatment 3: Selective Counterfactual\n",
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36eb4597-e07c-4a22-b93f-400b8f2bfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant prediction score average  0.7432187499895831\n",
      "risk assessment model prediction score average  0.7964548610833333\n",
      "performance gain  0.3781741059675701\n"
     ]
    }
   ],
   "source": [
    "scf_treatment = workers.loc[workers['treatment']==3]\n",
    "scf_avg = (sum(scf_treatment['participant_brier_score']) / len(scf_treatment))\n",
    "scf_ra_avg = (sum(scf_treatment['ra_brier_score']) / len(scf_treatment))\n",
    "print(\"participant prediction score average \",scf_avg)\n",
    "print(\"risk assessment model prediction score average \",scf_ra_avg)\n",
    "print(\"performance gain \", treatment_gain(scf_avg, baseline_avg, scf_ra_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f11d7137-29c9-4215-a14d-e457a41bf1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants in treatment and baseline\n",
      "t = 2.9663952574239496\n",
      "p = 0.0034064770032793856\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(scf_treatment['participant_brier_score']),list(baseline_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1bc2486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants in this treatment and risk assessment model only treatment\n",
      "t = -1.3258986373886041\n",
      "p = 0.1864905941081249\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(scf_treatment['participant_brier_score']),list(ra_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b827d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of performance difference between participants and risk assessment model in this treatment\n",
      "t = -6.343535926106329\n",
      "p = 1.603214359018354e-09\n"
     ]
    }
   ],
   "source": [
    "print('significance of performance difference between participants and risk assessment model in this treatment')\n",
    "t, p = stats.ttest_ind(list(scf_treatment['participant_brier_score']),list(scf_treatment['ra_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa5788",
   "metadata": {},
   "source": [
    "#### False Positive Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc6abccf-e387-431c-9f23-dba2c8000950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant false positive rate:  4.291666666666667\n",
      "average risk assessment model false positive rate:  3.2395833333333335\n"
     ]
    }
   ],
   "source": [
    "part_false_positive_avg = mean(workers.loc[workers['treatment']==3]['false_positive_participant'])\n",
    "ra_false_positive_avg = mean(workers.loc[workers['treatment']==3]['false_positive_ra_black'] + workers.loc[workers['treatment']==3]['false_positive_ra_white'])\n",
    "print('average participant false positive rate: ', part_false_positive_avg)\n",
    "print('average risk assessment model false positive rate: ', ra_false_positive_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae197b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in treatment and baseline\n",
      "t = -1.7866538118944646\n",
      "p = 0.07561343888338606\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==3]['false_positive_participant']),list(workers.loc[workers['treatment']==0]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f31dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in this treatment and risk assessment model only treatment\n",
      "t = -0.5320157226035148\n",
      "p = 0.5953466012283722\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==3]['false_positive_participant']),list(workers.loc[workers['treatment']==1]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f4482-c65d-4d3d-a2ef-1d726c91d4f7",
   "metadata": {},
   "source": [
    "### Treatment 4: Complete Feature Attribution\n",
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d71c1214-126c-43b8-bf18-ab87b60063b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant prediction score average  0.7566140350736843\n",
      "risk assessment prediction score average  0.7958947368631579\n",
      "performance gain  0.538159041089403\n"
     ]
    }
   ],
   "source": [
    "cpr_treatment = workers.loc[workers['treatment']==4]\n",
    "cpr_avg = (sum(cpr_treatment['participant_brier_score']) / len(cpr_treatment))\n",
    "cpr_ra_avg = (sum(cpr_treatment['ra_brier_score']) / len(cpr_treatment))\n",
    "print(\"participant prediction score average \", cpr_avg)\n",
    "print(\"risk assessment prediction score average \", cpr_ra_avg)\n",
    "print(\"performance gain \", treatment_gain(cpr_avg, baseline_avg, cpr_ra_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fb3a39e-f47b-450e-8b24-bec4726755f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of peformance difference between participants in treatment and baseline\n",
      "t = 4.945501763909773\n",
      "p = 1.6912520066908718e-06\n"
     ]
    }
   ],
   "source": [
    "print('significance of peformance difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(cpr_treatment['participant_brier_score']),list(baseline_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e69a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of peformance difference between participants in this treatment and risk assessment model only treatment\n",
      "t = 0.18780611120063762\n",
      "p = 0.8512333698443775\n"
     ]
    }
   ],
   "source": [
    "print('significance of peformance difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(cpr_treatment['participant_brier_score']),list(ra_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "918dbfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of peformance difference between participants and risk assessment model in this treatment\n",
      "t = -6.372814874373279\n",
      "p = 1.3960016989729182e-09\n"
     ]
    }
   ],
   "source": [
    "print('significance of peformance difference between participants and risk assessment model in this treatment')\n",
    "t, p = stats.ttest_ind(list(cpr_treatment['participant_brier_score']),list(cpr_treatment['ra_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba27f3d",
   "metadata": {},
   "source": [
    "#### False Positive Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24d97b54-f0f4-4efb-af2e-1dac388fa405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant false positive rate:  4.105263157894737\n",
      "average risk assessment model false positive rate:  3.231578947368421\n"
     ]
    }
   ],
   "source": [
    "part_false_positive_avg = mean(workers.loc[workers['treatment']==4]['false_positive_participant'])\n",
    "ra_false_positive_avg = mean(workers.loc[workers['treatment']==4]['false_positive_ra_black'] + workers.loc[workers['treatment']==4]['false_positive_ra_white'])\n",
    "print('average participant false positive rate: ', part_false_positive_avg)\n",
    "print('average risk assessment model false positive rate: ', ra_false_positive_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43ed4e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in treatment and baseline\n",
      "t = -2.113075082680535\n",
      "p = 0.03592811927903101\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==4]['false_positive_participant']),list(workers.loc[workers['treatment']==0]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b65b0eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in this treatment and risk assessment model only treatment\n",
      "t = -0.9430390457509231\n",
      "p = 0.34688421776220957\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==4]['false_positive_participant']),list(workers.loc[workers['treatment']==1]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2348e-3cd1-45d0-885d-37516c7dd471",
   "metadata": {},
   "source": [
    "### Treatment 5: Selective Feature Attribution\n",
    "#### Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd078320-3d3b-462d-839b-4832c5275a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant prediction score average:  0.7505017920645162\n",
      "risk assessment model prediction score average:  0.7954372759892476\n",
      "performance gain:  0.46881620108865957\n"
     ]
    }
   ],
   "source": [
    "spr_treatment = workers.loc[workers['treatment']==5]\n",
    "spr_avg = (sum(spr_treatment['participant_brier_score']) / len(spr_treatment))\n",
    "spr_ra_avg = (sum(spr_treatment['ra_brier_score']) / len(spr_treatment))\n",
    "print(\"participant prediction score average: \",spr_avg)\n",
    "print(\"risk assessment model prediction score average: \",spr_ra_avg)\n",
    "print(\"performance gain: \", treatment_gain(spr_avg, baseline_avg, spr_ra_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c5f5148-d41c-443f-bace-deb9b8dc43ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of peformance difference between participants in treatment and baseline\n",
      "t = 3.662455693920708\n",
      "p = 0.0003264363998128492\n"
     ]
    }
   ],
   "source": [
    "print('significance of peformance difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(spr_treatment['participant_brier_score']),list(baseline_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "134c6cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of peformance difference between participants in this treatment and risk assessment model only treatment\n",
      "t = -0.5363333032454781\n",
      "p = 0.5923760364424032\n"
     ]
    }
   ],
   "source": [
    "print('significance of peformance difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(spr_treatment['participant_brier_score']),list(ra_treatment['participant_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88943fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of peformance difference between participants and risk assessment model in this treatment\n",
      "t = -5.417239936006993\n",
      "p = 1.8771365535670148e-07\n"
     ]
    }
   ],
   "source": [
    "print('significance of peformance difference between participants and risk assessment model in this treatment')\n",
    "t, p = stats.ttest_ind(list(spr_treatment['participant_brier_score']),list(spr_treatment['ra_brier_score']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715820d",
   "metadata": {},
   "source": [
    "#### False Positive Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93817a6b-a0d3-4fed-9c10-dacfeeb03058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average participant false positive rate:  3.870967741935484\n",
      "average risk assessment model false positive rate:  3.3225806451612905\n"
     ]
    }
   ],
   "source": [
    "part_false_positive_avg = mean(workers.loc[workers['treatment']==5]['false_positive_participant'])\n",
    "ra_false_positive_avg = mean(workers.loc[workers['treatment']==5]['false_positive_ra_black'] + workers.loc[workers['treatment']==5]['false_positive_ra_white'])\n",
    "print('average participant false positive rate: ', part_false_positive_avg)\n",
    "print('average risk assessment model false positive rate: ', ra_false_positive_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb816af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in treatment and baseline\n",
      "t = -2.5524834718418834\n",
      "p = 0.011507876812880645\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in treatment and baseline')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==5]['false_positive_participant']),list(workers.loc[workers['treatment']==0]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44cb946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significance of false positive rate difference between participants in this treatment and risk assessment model only treatment\n",
      "t = -1.5155158579369528\n",
      "p = 0.1313578300829341\n"
     ]
    }
   ],
   "source": [
    "print('significance of false positive rate difference between participants in this treatment and risk assessment model only treatment')\n",
    "t, p = stats.ttest_ind(list(workers.loc[workers['treatment']==5]['false_positive_participant']),list(workers.loc[workers['treatment']==1]['false_positive_participant']))\n",
    "print(\"t = \" + str(t))\n",
    "print(\"p = \" + str(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cf",
   "language": "python",
   "name": "cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
